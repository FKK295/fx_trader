name: Model Retraining

on:
  schedule:
    # Example: Run every Sunday at 00:00 UTC
    - cron: "0 0 * * 0"
  workflow_dispatch: # Allows manual triggering
  # repository_dispatch: # Allows triggering via webhook / external event
  #   types: [trigger-retraining]

jobs:
  retrain-model:
    runs-on: ubuntu-latest
    # Add environment variables if your retraining script needs them (e.g., API keys for data fetching)
    # These should be GitHub secrets
    # environment:
    #   name: production # Or staging, if you have GitHub environments
    # env:
    #   OANDA_ACCESS_TOKEN: ${{ secrets.OANDA_ACCESS_TOKEN }}
    #   FRED_API_KEY: ${{ secrets.FRED_API_KEY }}
    #   MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }} # Or use the one from docker-compose for local testing
    #   AWS_ACCESS_KEY_ID: ${{ secrets.MINIO_ACCESS_KEY }} # For MLflow artifacts if MinIO is external
    #   AWS_SECRET_ACCESS_KEY: ${{ secrets.MINIO_SECRET_KEY }}

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.10" # Choose a specific version for retraining consistency

    - name: Install Poetry
      uses: snok/install-poetry@v1

    - name: Install dependencies
      run: poetry install --no-dev --sync --no-interaction --no-ansi # No dev/test deps needed for retraining script usually

    - name: Install TA-Lib (system dependency)
      run: |
        sudo apt-get update
        sudo apt-get install -y libta-lib-dev
        # poetry install --no-dev --sync --no-interaction --no-ansi # Re-install if TA-Lib python wrapper needs it

    - name: Run Retraining Script
      # This assumes your mlops.retrain script can run and connect to necessary services (Feast, MLflow)
      # You might need to set up service containers (like in docker-compose) if they are not externally accessible.
      # For a CI environment, MLflow/Feast might point to staging/prod instances.
      run: |
        poetry run python -m fx_trader.mlops.retrain \
          --feast_repo feature_store \
          --ref_entities path/to/production_model_training_entities.parquet \
          --curr_entities path/to/latest_data_for_drift_check.parquet \
          --experiment "FX_Scheduled_Retraining"
      # The paths to entity files need to be accessible, e.g., downloaded from S3/MinIO or checked into git (if small)

    - name: Check for new model and create PR (Optional)
      # This step is complex and highly custom.
      # It would involve:
      # 1. Checking MLflow Model Registry for a newly registered model from the retraining run.
      # 2. If a new model is registered and meets criteria (e.g., better metrics):
      #    - Potentially update a model version file in the repo.
      #    - Create a pull request using an action like `peter-evans/create-pull-request`.
      id: check_new_model
      run: |
        echo "Checking for new model in MLflow..."
        # Add script here to query MLflow API for new model versions in 'Staging' or a specific tag.
        # Example: NEW_MODEL_REGISTERED=$(python -m your_mlflow_check_script)
        # echo "::set-output name=new_model_registered::$NEW_MODEL_REGISTERED"
        echo "::set-output name=new_model_registered::false" # Placeholder

    - name: Create Pull Request for Model Update
      if: steps.check_new_model.outputs.new_model_registered == 'true'
      uses: peter-evans/create-pull-request@v5
      with:
        token: ${{ secrets.PAT_FOR_CREATE_PR }} # A Personal Access Token with repo write scope
        commit-message: "feat: Update production model after retraining"
        branch: "feature/auto-model-update"
        base: "develop" # Or 'main'
        title: "Automated Model Update"
        body: |
          A new model has been trained and registered by the automated retraining workflow.
          Please review and merge to deploy.
          - Link to MLflow run: MLflow Run
          - Key metrics improvements: ...
        labels: model-update, automated-pr
        draft: false